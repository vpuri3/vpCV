\documentclass[10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{enumitem}
\geometry{
    letterpaper,
    lmargin=0.70in,
    rmargin=0.70in,
    tmargin=0.65in,
    bmargin=0.70in
}

\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

\setlength{\parindent}{0pt}
\setlength{\parskip}{0.08em}
\pagenumbering{gobble}
\setlist[itemize]{leftmargin=1.45em,labelsep=0.5em,itemsep=0.05em,topsep=0.05em,parsep=0em,partopsep=0em}

% \newcommand{\cvsection}[1]{%
%   \vspace{0.2em}%
%   {\normalsize\textsc{#1}}\\[-0.50em]
%   \rule{\linewidth}{0.4pt}
%   \vspace{-0.25em}
% }

\newcommand{\cvsection}[1]{%
  \vspace{0.30em}%
  {\large\textsc{#1}}\\[-0.90em]
  \rule{\linewidth}{0.4pt}
  \vspace{-0.15em}
}

\newcommand{\cvrole}[3]{\textbf{#1} $|$ \textit{#2}\hfill #3}
\newcommand{\cvskill}[2]{\textbf{#1}: #2}

\begin{document}

{\Huge \textsc{Vedant Puri}}\hfill
\href{mailto:vedantpuri@cmu.edu}{\texttt{vedantpuri@cmu.edu}} $|$
\href{https://vpuri3.github.io/}{\texttt{https://vpuri3.github.io/}}

\cvsection{Objective}
PhD candidate graduating August 2026 seeking a technical role in machine learning architecture research.
Experience designing scalable transformer architectures in PyTorch and implementing them in Triton.
Background in high-performance computing, numerical analysis, and computational fluid dynamics.

\cvsection{Education}
\textbf{Carnegie Mellon University}\hfill Jan 2022--Present
\begin{itemize}[label=]
  \item \textit{Ph.D Mechanical Engineering}.
  Advisors: Levent Burak Kara, Yongjie Jessica Zhang
  \item Proposed thesis: \textit{Neural representations for computational physics: from reduced order modeling to transformers}
\end{itemize}

\textbf{University of Illinois Urbana-Champaign}\hfill 2015--2019
\begin{itemize}[label=]
  \item \textit{B.S. Engineering Mechanics}, \textit{B.S. Mathematics}.
  %\item Minor: \textit{Computational Science and Engineering}
\end{itemize}

\cvsection{Selected Research Contributions}
\cvrole{FLARE: Fast Low-Rank Attention Routing Engine}{Efficient attention architectures}{2025}
\begin{itemize}[leftmargin=1.45em,labelindent=0.45em]
  \item Derived a flexible low-rank reformulation of self-attention via latent routing.
  \item Reduced quadratic complexity of global communication in self-attention to linear complexity.
  \item Demonstrated scaling to 1M tokens on a single H100 GPU, attaining over $200\times$ speedup over vanilla self-attention.
  % \item \textbf{Ongoing}: extending FLARE to decoder-only language modeling; adapting low-rank attention mechanisms for autoregressive training and memory-constrained inference paths using fused Triton kernels.
\end{itemize}

\cvrole{FLARE for Language Modeling (Ongoing dissertation work)}{Decoder-only architectures}{2025--Present}
\begin{itemize}[leftmargin=1.45em,labelindent=0.45em]
  \item Extending FLARE to decoder-only next-token prediction with causal attention.
  \item Enabling adaptive attention state size to control memory and compute during training and inference.
  \item Implementing fused Triton kernels for causal training, prefill, and decode.
\end{itemize}

\cvrole{Equation-based PDE modeling with neural fields}{Hybrid data + physics methods}{2025}
\begin{itemize}[leftmargin=1.45em,labelindent=0.45em]
  \item Introduced smooth neural fields as nonlinear spatial ansatz functions in equation-based reduced-order modeling.
  \item Retained physics-based Galerkin time evolution while learning expressive low-dimensional representations.
  \item Attained $199\times$ speedup over full-order simulations in transport-dominated regimes.
\end{itemize}

\cvsection{Experience}
%
\cvrole{Carnegie Mellon University}{Research Assistant}{Jan 2022--Present}
\begin{itemize}[leftmargin=1.45em,labelindent=0.45em]
  % \item Efficient attention architectures for scientific computing.
  % \item Equation-based reduced order modeling for computational fluid dynamics.
  \item Phase field simulations of lithium dendritic growth in solid-state batteries.
  \item Turbulence closure modeling with differentiable physics.
\end{itemize}
%
\cvrole{Julia Computing}{Intern Engineer}{Apr 2021--Nov 2021}
\begin{itemize}[leftmargin=1.45em,labelindent=0.45em]
  \item Built numerical solvers for scientific machine learning ecosystem in Julia.
  %\item Wrote the linear solve interface for Julia \texttt{SciML.ai} ecosystem.
  %\item Developed differentiable geometry representations and automated meshing algorithms.
  %\item Developed deep learning surrogate models for solving partial differential equations.
\end{itemize}

\cvrole{Carnegie Mellon University}{Research Assistant}{Sep 2020--Jan 2021}
\begin{itemize}[leftmargin=1.45em,labelindent=0.45em]
  %\item Wrote \href{https://github.com/vpuri3/SpectralElements.jl}{\texttt{SpectralElements.jl}}, a differentiable PDE solver for machine learning research.
  \item Developed differentiable geometry representations and meshing algorithms.
\end{itemize}

\cvrole{Argonne National Laboratory}{Research Assistant}{Mar 2020--Sep 2020}
\begin{itemize}[leftmargin=1.45em,labelindent=0.45em]
  \item Executed large-scale simulations of turbulent airflow over urban landscapes on supercomputers.
  %\item Fluid dynamics simulations (LES, RANS) of turbulent airflow in urban landscapes.
  %\item Meshing, setup, benchmarking, and analysis in OpenFOAM and \textsc{Nek5000}.
\end{itemize}

\cvrole{Argonne National Laboratory}{Research Assistant}{May 2018--Jul 2018}
\begin{itemize}[leftmargin=1.45em,labelindent=0.45em]
  \item Executed high-fidelity fluid dynamics simulations and analyzed turbulent statistics for closure modeling.
  % \item Fluid dynamics simulations of airflow over windfarm terrains on supercomputers.
  % \item Analysed Reynolds stress budgets in canonical flows for turbulence model development.
  %\item Developed \href{https://github.com/vpuri3/NekTools}{\texttt{NekTools}}, a FORTRAN 77 toolbox for post-processing \textsc{Nek5000} simulations.
\end{itemize}

\cvrole{National Center for Supercomputing Applications}{Intern}{Sep 2017--May 2018}
\begin{itemize}[leftmargin=1.45em,labelindent=0.45em]
  \item Numerical simulation of spacetime metric for gravitational wave simulations.
  %\item Implemented preconditioning and relaxation methods for nonlinear PDEs.
\end{itemize}

%\cvrole{Mechanical Science \& Engineering, UIUC}{Course Assistant}{Jan 2016--Dec 2017}
%\begin{itemize}[leftmargin=1.45em,labelindent=0.45em]
%  \item Taught mechanical analysis using free-body diagrams and control volumes for Statics.
%  \item Created instructional demonstrations for engineering courses serving 2500 students annually.
%\end{itemize}

% \cvsection{Teaching}
% \cvrole{Carnegie Mellon University}{Teaching Assistant, Numerical Analysis}{Spring 2025, Spring 2026}

% \cvrole{Carnegie Mellon University}{Teaching Assistant, Discrete Differential Geometry}{Spring 2023}

% % \cvrole{University of Illinois}{Course Assistant, Introductory Statics}{Spring 2016--Fall 2017}

\cvsection{Publications}
\textbf{Puri, V}. et al., \textit{Low-rank attention routing for causal language modeling} (In preparation).

\textbf{Puri, V}. et al., \textit{FLARE: Fast Low-Rank Attention Routing Engine}. \href{https://arxiv.org/abs/2508.12594}{arXiv:2508.12594} (2025) (Under review).

\textbf{Puri, V}. et al., \textit{SNF-ROM: Reduced order modeling with smooth neural fields}. JCP 2025, \href{https://doi.org/10.1016/j.jcp.2025.113957}{doi:10.1016/j.jcp.2025.113957}.

S, V., \textbf{Puri, V.}, et al., \textit{Closure modeling for Burgers' turbulence}. MLST 2023, \href{https://doi.org/10.1088/2632-2153/acb19c}{doi:10.1088/2632-2153/acb19c}.

\cvsection{Awards}
\cvrole{World Conference on Computational Mechanics}{Best poster in fluid dynamics}{2024}

\cvrole{University of Illinois}{Theoretical and Applied Mechanics Merit Award}{2019}

% \cvrole{Society for Engineering Mechanics, UIUC}{President}{2019}

%\cvrole{Society for Engineering Mechanics, UIUC}{Curriculum Development}{2017--2018}

\cvsection{Technical Skills}
% \cvskill{GPU Programming}{Triton}
\cvskill{Machine Learning Systems}{PyTorch, Triton, mixed-precision/distributed training, causal language modeling}

\cvskill{Numerical Computing}{Numerical analysis, scientific computing, linear algebra, finite elements, spectral methods}

\cvskill{Programming Languages}{Python, Julia, C, Fortran 77, MATLAB, UNIX, \LaTeX}

\cvskill{Modeling Domains}{Transformer architectures, neural operators, reduced-order modeling}

%\cvskill{Languages}{English (fluent), Hindi (native)}

\end{document}
